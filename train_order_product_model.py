import pandas as pd
import pickle
import os
from elasticsearch import Elasticsearch
from sklearn.metrics.pairwise import cosine_similarity
from xgboost import XGBRegressor
from prophet import Prophet
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.arima.model import ARIMA
from config import Config
from datetime import datetime
from dateutil.relativedelta import relativedelta

from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeRegressor
from xgboost import XGBRegressor

from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from scipy.sparse import csr_matrix

model_dir = "/app/model_storage/predict"
os.makedirs(model_dir, exist_ok=True)

def fetch_all_es_data(index_name, es, scroll='2m', size=1000):
    all_data = []
    page = es.search(
        index=index_name,
        scroll=scroll,
        size=size,
        body={"query": {"match_all": {}}}
    )
    sid = page['_scroll_id']
    hits = page['hits']['hits']
    all_data.extend(hits)

    while len(hits) > 0:
        page = es.scroll(scroll_id=sid, scroll=scroll)
        sid = page['_scroll_id']
        hits = page['hits']['hits']
        all_data.extend(hits)

    return [doc['_source'] for doc in all_data]

def train_predict_model_and_save(algo_name: str):
    # if algo_name in ["linear", "logistic", "tree", "xgb"]:
    #     return train_standard_model(algo_name)
    # el
    timeseries_algos = ["xgb_timeseries", "prophet", "arima", "sarimax"]
    if algo_name in timeseries_algos:
        return train_timeseries_model(algo_name)
    else:
        raise ValueError(f"Unsupported or invalid algorithm: {algo_name}")

def train_timeseries_model(algo_name: str):

    es = Elasticsearch(Config.ELASTICSEARCH_URI)
    index_name = "order_products-logs"
    data = fetch_all_es_data(index_name, es)
    df = pd.DataFrame(data)

    # ë‚ ì§œ ë³€í™˜ ë° í•„í„°ë§
    df["timestamp"] = pd.to_datetime(df["timestamp"])
    df["year_month"] = df["timestamp"].dt.to_period("M")

    # ì›”ë³„ íŒë§¤ëŸ‰ ì§‘ê³„
    monthly_sales = df.groupby(["productName", "year_month"])["productQuantity"].sum().reset_index()
    monthly_sales["year_month"] = monthly_sales["year_month"].astype(str)
    monthly_sales["year_month"] = pd.to_datetime(monthly_sales["year_month"])
    monthly_sales = monthly_sales.sort_values(["productName", "year_month"])

    models = {}

    for product in monthly_sales["productName"].unique():
        df_product = monthly_sales[monthly_sales["productName"] == product].copy()
        # ëˆ„ë½ëœ ì›” ì±„ìš°ê¸° (ë³´ê°„)
        all_months = pd.date_range(
            start=monthly_sales["year_month"].min(),
            end=monthly_sales["year_month"].max(),
            freq="MS"
        )
        # ë‚ ì§œë¥¼ indexë¡œ ë°”ê¿”ì„œ ì‹œê³„ì—´ ì²˜ëŸ¼ ë‹¤ë£¨ê¸° ì‰½ë„ë¡ í•¨
        df_product = df_product.set_index("year_month").reindex(all_months)
        df_product.index.name = "year_month"
        df_product["productName"] = product
        # ëˆ„ë½ ë˜ì—ˆë˜ ì›”ì˜ productQuantity ë¶€ë¶„ì˜ ë°ì´í„° ì„ í˜• ë³´ê°„
        df_product["productQuantity"] = df_product["productQuantity"].astype(float).interpolate(method="linear")
        # indexë¡œ ë³€í–ˆë˜ ë¶€ë¶„ì„ ë‹¤ì‹œ ì¼ë°˜ ì»¬ëŸ¼ìœ¼ë¡œ ë˜ëŒë¦¼
        df_product = df_product.reset_index()

        if len(df_product) < 1:
            continue  # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ìŠ¤í‚µ

        if algo_name == "xgb_timeseries":
            # lag feature ìƒì„±
            n_lags = 3
            for lag in range(1, n_lags + 1):
                df_product[f"lag_{lag}"] = df_product["productQuantity"].shift(lag)
            df_product["target"] = df_product["productQuantity"].shift(-1)
            df_product.dropna(inplace=True)

            X = df_product[["lag_1", "lag_2", "lag_3"]]
            y = df_product["target"]
            model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, objective='reg:squarederror')
            model.fit(X, y)

            last_date = df_product["year_month"].max()

            # í–¥í›„ 4ê°œì›” ì˜ˆì¸¡
            future_preds = []
            last_vals = list(df_product.iloc[-3:]["productQuantity"])
            for _ in range(4):
                x_input = pd.DataFrame([last_vals[-3:]], columns=["lag_1", "lag_2", "lag_3"])
                pred = model.predict(x_input)[0]
                future_preds.append(pred)
                last_vals.append(pred)

            models[product] = {
                "model": model,
                "last_vals": df_product.iloc[-3:]["productQuantity"].tolist(),
                "predictions": future_preds,
                "last_date" : last_date
            }

        elif algo_name == "prophet":
            df_prophet = df_product.rename(columns={"year_month": "ds", "productQuantity": "y"})
            model = Prophet()
            model.fit(df_prophet)

            last_date = df_prophet["ds"].max()
            future = pd.date_range(start=last_date + relativedelta(months=1), periods=4, freq="MS")
            future_df = pd.DataFrame({"ds": future})

            forecast = model.predict(future_df)
            preds = forecast["yhat"].tolist()

            models[product] = {
                "model": model,
                "predictions": preds,
                "last_date" : last_date
            }
        elif algo_name == "arima":
            try:
                model = ARIMA(df_product["productQuantity"], order=(1, 1, 1))
                model_fit = model.fit()
                forecast = model_fit.forecast(steps=4)
                last_date = df_product["year_month"].max()

                models[product] = {
                    "model": model_fit,
                    "predictions": forecast.tolist(),
                    "last_date" : last_date
                }
            except Exception as e:
                print(f"ARIMA failed for {product}: {e}")
                continue

        elif algo_name == "sarimax":
            try:
                model = SARIMAX(df_product["productQuantity"], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))
                model_fit = model.fit(disp=False)
                forecast = model_fit.forecast(steps=4)
                last_date = df_product["year_month"].max()
                models[product] = {
                    "model": model_fit,
                    "predictions": forecast.tolist(),
                    "last_date": last_date
                }
            except Exception as e:
                print(f"SARIMAX failed for {product}: {e}")
                continue

    # ğŸ”¹ ì €ì¥
    model_path = os.path.join(model_dir, f"model_{algo_name}.pkl")
    with open(model_path, "wb") as f:
        pickle.dump(models, f)

    print(models.keys())
    return {"message": f"{algo_name} time series model trained and saved."}

# def get_model_by_name(algo_name: str):
#     if algo_name == "linear":
#         return LinearRegression()
#     elif algo_name == "logistic":
#         return LogisticRegression()
#     elif algo_name == "tree":
#         return DecisionTreeRegressor()
#     elif algo_name == "xgb":
#         return XGBRegressor()
#     else:
#         raise ValueError(f"Unsupported algorithm: {algo_name}")

# def train_standard_model(algo_name: str):
#     es = Elasticsearch("http://localhost:9200")
#     index_name = "order_products-logs"
#
#     res = es.search(index=index_name, body={"size": 10000, "query": {"match_all": {}}})
#     data = [hit['_source'] for hit in res['hits']['hits']]
#     df = pd.DataFrame(data)
#
#     # ğŸ”¹ ë‚ ì§œ ì „ì²˜ë¦¬
#     df["timestamp"] = pd.to_datetime(df["timestamp"])
#     df["month"] = df["timestamp"].dt.month
#     df["year_month"] = df["timestamp"].dt.to_period("M")
#
#     # ğŸ”¹ ì„±ë³„ ì „ì²˜ë¦¬ (ë‚¨: 0, ì—¬: 1)
#     df["userGender"] = df["userGender"].map({"ë‚¨": 0, "ì—¬": 1})
#
#     # ğŸ”¹ ì „ì›” íŒë§¤ëŸ‰ ê³„ì‚° â†’ ì¦ê°€ìœ¨ (product ê¸°ì¤€)
#     monthly_sales = df.groupby(["productName", "year_month"])["productQuantity"].sum().reset_index()
#     monthly_sales["prev_month_qty"] = monthly_sales.groupby("productName")["productQuantity"].shift(1)
#     monthly_sales["increase_rate"] = (
#         (monthly_sales["productQuantity"] - monthly_sales["prev_month_qty"]) /
#         monthly_sales["prev_month_qty"]
#     ).fillna(0)
#
#     # ğŸ”¹ ì›ë³¸ dfì™€ ë³‘í•©
#     df["year_month"] = df["timestamp"].dt.to_period("M")
#     df = pd.merge(df, monthly_sales[["productName", "year_month", "increase_rate"]],
#                   on=["productName", "year_month"], how="left")
#
#     df["increase_rate"] = df["increase_rate"].fillna(0)
#
#     # ğŸ”¹ í•„ìš”í•œ ì—´ë§Œ ì¶”ì¶œ
#     features = ["userAge", "productPrice", "userGender", "userRegion", "month", "increase_rate"]
#     df_model = df[features + ["productName", "productQuantity"]]
#
#     # ğŸ”¹ í•™ìŠµìš© ë°ì´í„° ì¤€ë¹„: ì œí’ˆë³„ í‰ê· ê°’ ì‚¬ìš©
#     df_grouped = df_model.groupby("productName").agg({
#         "userAge": "mean",
#         "productPrice": "mean",
#         "userGender": "mean",
#         "month": "mean",
#         "increase_rate": "mean",
#         "userRegion": lambda x: x.mode()[0],  # ìµœë¹ˆê°’ ì‚¬ìš©
#         "productQuantity": "sum"
#     }).reset_index()
#
#     # ğŸ”¹ Feature / Target êµ¬ë¶„
#     X = df_grouped[["userAge", "productPrice", "userGender", "userRegion", "month", "increase_rate"]]
#     y = df_grouped["productQuantity"]
#
#     # ğŸ”¹ ë²”ì£¼í˜• ì¸ì½”ë”© (userRegion)
#     categorical_features = ["userRegion"]
#     numeric_features = ["userAge", "productPrice", "userGender", "month", "increase_rate"]
#
#     preprocessor = ColumnTransformer(transformers=[
#         ("cat", OneHotEncoder(handle_unknown="ignore"), categorical_features),
#     ], remainder="passthrough")
#
#     model = get_model_by_name(algo_name)
#
#     # ğŸ”¹ íŒŒì´í”„ë¼ì¸ êµ¬ì„±
#     pipeline = Pipeline(steps=[
#         ("preprocessor", preprocessor),
#         ("model", model)
#     ])
#
#     pipeline.fit(X, y)
#
#     # ğŸ”¹ ì €ì¥
#     model_path = os.path.join(model_dir, f"model_{algo_name}.pkl")
#     with open(model_path, "wb") as f:
#         pickle.dump((pipeline, df_grouped), f)
#
#     return {"message": f"{algo_name} model trained and saved."}
